<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yongkang Cheng</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yongkang Cheng „ÄåÊàêÊ∞∏Â∫∑„Äç</name>
              </p>
               <!-- <p>ü§ì Hi, there! I am Yongkang. I am now a first-year PhD student at MBZUAI and I am a Research Intern at <a href="https://www.astribot.com/">Astribot, Interaction Group.</a> I am also a coming PhD student at the <a href="https://mbzuai.ac.ae/">Mohamed bin Zayed University of Artificial Intelligence (MBZUAI)</a>, supervised by Professor <a href="https://mingming-gong.github.io/">Mingming Gong</a>. Prior to this, I worked as a research intern at <a href="https://ailab.tencent.com/ailab/zh/index">the Digital Human Center of Tencent AILab</a>, with Dr. <a href="https://shaoli-huang.github.io/">Shaoli Huang</a> as my supervisor. I obtained my bachelor's degree from <a href="https://www.njau.edu.cn/">Nanjing Agricultural University</a> in 2021 and my master's degree from <a href="https://www.nwsuaf.edu.cn/">Northwest A&F University</a> in 2024. My research interests include computer vision and generative models, especially motion capture and motion generation of digital humans. Recently, I have been researching humanoid robots during interaction.
               </p> -->
               <p>ü§ì Hi, there! I am Yongkang. I am now a first-year PhD student at MBZUAI. Prior to this, I worked as a research intern at <a href="https://ailab.tencent.com/ailab/zh/index">the Digital Human Center of Tencent AILab</a>, with Dr. <a href="https://shaoli-huang.github.io/">Shaoli Huang</a> as my supervisor. I obtained my bachelor's degree from <a href="https://www.njau.edu.cn/">Nanjing Agricultural University</a> in 2021 and my master's degree from <a href="https://www.nwsuaf.edu.cn/">Northwest A&F University</a> in 2024. My research interests include computer vision and generative models, especially motion capture and motion generation of digital humans. Recently, I have been researching humanoid robots during interaction.
               </p>
<!--                <p style="color:red; font-weight:bold;">
                  I will be joining MBZUAI to pursue a PhD degree in August !!!
<!-- 		       I am pursuing PhD opportunities for 2026 admission !!! -->
               </p>
                <p> Email: cyk19990422 at gmail dot com </p>
              <p style="text-align:center">
                <a href="mailto:zhang163220@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=cv5O1n0AAAAJ&hl=zh-CN&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/cyk990422">Github</a> &nbsp/&nbsp
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/yongkangcheng.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/11pro.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>üë£ Services</heading><p>
                Journal Reviewers: IJCV; PR; TCSVT  <br>
                Conference Reviewers: ICME; ICIP; ACM MM; WACV; AAAI
            </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
         <tr>
         <td style="padding:20px;width:100%;vertical-align:middle">
           <heading>üî• News</heading><p>
<!-- 			[Jun. 2025] I am now a Research Scientist at Agibot.  <br> -->
            [May. 2025] 2 JCR Q1 papers are accepted to Pattern Recognition 2025.  <br>
<!--             [May. 2025] 1 CCF-B paper is accepted to ICMR 2025. (Project Leader) <br> -->
<!--             [Feb. 2025] I have received a 2025 Fall PhD offer in Machine Learning from MBZUAI.  <br>
            [Jan. 2025] I will intern at Astribot.  <br> -->
            [Dec. 2024] 1 CCF-A paper is accepted to AAAI 2025. <br>
            [Nov. 2024] 1 CCF-C paper is accepted to 3DV 2025.  <br>
            [Aug. 2024] 3 papers are accepted to WACV 2025.<br>
<!-- 	    [Jul. 2024] 1 CCF-C paper is accepted to MMA 2024(oral).<br> -->
            [Jul. 2024] 1 CCF-B paper is accepted to ECCV 2024.<br>
            [Mar. 2024] 1 CCF-B paper is accepted to ICME 2024.<br>
            [Jan. 2024] 1 CCF-B paper is accepted to ICASSP 2024.<br>
            [Dec. 2023] 1 JCR Q1 paper is accepted to TCSVT 2023.<br>
<!--             [Aug. 2022] I will intern at Digital Human Center @ Tencent AILab. <br>
            [Feb. 2021] 1 paper is accepted to EI 2020<br> -->
            
         </p>
         </td>
       </tr>
     </tbody></table>

     <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>üî• Project</heading><p>
      </td>
   </tr>
   <table class="publication-table">
         <td class="image-column">
            <div class="demo-video">
               <img src="./images/5.jpg" class="publication-image", style="width: 300px; height: 120px;">
            </div>
         </td>
         <td class="description-column">
               <div class="paper_title">The AGG Leaderboard - an Extended, Living Benchmark for Evaluating and Advancing Automatic Gesture Generation</div>
               <div class="paper_venue"> <b><p style="color:red; font-weight:bold;">The world's 3rd-ranked, and China's best model.</p></b> </div>
            <div class="paper_materials">
               <span class="link"><a target=_blank href="https://cyk990422.github.io/HoloGest.github.io/">[Our Project]</a></span>
         </div>
         </td>
         </tr>
      </p>
      </td>
<!--       <td class="image-column">
         <div class="demo-video">
            <img src="./images/Video1.gif" class="publication-image", style="width: 300px; height: 280px;">
         </div>
      </td>
      <td class="description-column">
            <div class="paper_title">Talking Astribot-S1 Robot (The generative model is based on <a href="https://cyk990422.github.io/HoloGest.github.io/">Hologest.)</div>
            <div class="paper_venue"> <b>First Author: Yongkang Cheng</b> (Astribot Interacting Team) </div>
      </td>
      </tr>
   </p>
   </td> -->
    </tr>
  </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>üéâ Selected Publications</heading>
            </td>
          </tr>
        </tbody></table>

        <table class="publication-table">

         <tr>
                  <td class="image-column">
                     <div class="demo-video">
                        <img src="./images/bopr.gif" class="publication-image", style="width: 200px; height: auto;">
                     </div>
                  </td>
                  <td class="description-column">
                        <div class="paper_title">ReBaR: Reference-Based Reasoning for Robust Pose Estimation from Monocular Images</div>
                        <div class="paper_authors">
                            <b>Yongkang Cheng</b>, Mingjiang Liang‚Ä†, Jifeng Ning, Gaoge Han, WeiLiu, Shaoli Huang‚Ä†
                        </div>
                        <div class="paper_venue"> <b>Pattern Recognition 2025 <p style="color:red; font-weight:bold;">(My first work !)</p></b> </div>
                     <div class="paper_materials">
                     <span class="link"><a target=_blank href="https://arxiv.org/abs/2303.11675">[Paper]</a></span>
                         <span class="link"><a target=_blank href="https://semanticdh.github.io/BoPR/">[Project]</a></span>
                     </div>
                  </td>
                  </tr>


		<tr>
            <td class="image-column">
               <div class="demo-video">
                  <img src="./images/rebuttal.png" class="publication-image", style="width: 200px; height: 120px;">
               </div>
            </td>
            <td class="description-column">
                  <div class="paper_title">Aligning Foundation Model Priors and Diffusion-Based Hand Interactions for Occlusion-Resistant Two-Hand Reconstruction</div>
                  <div class="paper_authors">
                  Gaoge Han, <b>Yongkang Cheng</b>, Zhe Chen, Shaoli Huang‚Ä†, Tongliang Liu
                  <div class="paper_venue"> <b>Under Review</b> </div>
               <div class="paper_materials">
                  <span class="link"><a target=_blank href="https://arxiv.org/abs/2503.17788">[Paper]</a></span>
            </div>
            </td>
            </tr>

            <tr>
            <td class="image-column">
               <div class="demo-video">
                  <img src="./images/3dv2025.gif" class="publication-image", style="width: 200px; height: 120px;">
               </div>
            </td>
            <td class="description-column">
                  <div class="paper_title">HoloGest: Decoupled Diffusion and Motion Priors for Generating Holisticly Expressive Co-speech Gestures</div>
                  <div class="paper_authors">
                  <b>Yongkang Cheng</b>, Shaoli Huang‚Ä†
                  <div class="paper_venue"> <b>3DV 2025</b> </div>
               <div class="paper_materials">
                  <span class="link"><a target=_blank href="https://arxiv.org/abs/2503.13229">[Paper]</a></span>
                  <span class="link"><a target=_blank href="https://cyk990422.github.io/HoloGest.github.io/">[Project]</a></span>
                  <span class="link"><a target=_blank href="https://github.com/cyk990422/Efficient-Audio-Gesture">[Code]</a></span>
            </div>
            </td>
            </tr>

            <tr>
            <td class="image-column">
               <div class="demo-video">
                  <img src="./images/aaai2025.gif" class="publication-image", style="width: 200px; height: 120px;">
               </div>
            </td>
            <td class="description-column">
                  <div class="paper_title">DIDiffGes: Decoupled Semi-Implicit Diffusion Models for Real-time Gesture Generation from Speech</div>
                  <div class="paper_authors">
                  <b>Yongkang Cheng</b>, Shaoli Huang‚Ä†, Xuelin Chen, Jifeng Ning, Mingming Gong
                  </div>
                  <div class="paper_venue"> <b>AAAI 2025</b> </div>
               <div class="paper_materials">
                   <span class="link"><a target=_blank href="https://arxiv.org/abs/2503.17059">[Paper]</a></span>
                   <span class="link"><a target=_blank href="https://cyk990422.github.io/DIDiffGes/">[Project]</a></span>
                  <span class="link"><a target=_blank href="https://github.com/cyk990422/Efficient-Audio-Gesture">[Code]</a></span>
            </div>
            </td>
            </tr>

            <tr>
            <td class="image-column">
               <div class="demo-video">
                  <img src="./images/wacv2025egg.png" class="publication-image", style="width: 200px; height: auto;">
               </div>
            </td>
            <td class="description-column">
                  <div class="paper_title">Conditional GAN for Enhancing Diffusion Models in Efficient and Authentic Global Gesture Generation from Audios</div>
                  <div class="paper_authors">
                     <b>Yongkang Cheng</b>, Mingjiang Liang, Shaoli Huang‚Ä†, Gaoge Han, Jifeng Ning, Wei Liu
                  <div class="paper_venue"> <b>WACV 2025</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/abs/2410.20359">[Paper]</a></span>
            </div>
            </td>
            </tr>

            <tr>
            <td class="image-column">
               <div class="demo-video">
                  <img src="./images/wacv2025rope.png" class="publication-image", style="width: 200px; height: auto;">
               </div>
            </td>
            <td class="description-column">
                  <div class="paper_title">RopeTP: Global Human Motion Recovery via Integrating Robust Pose Estimation with Diffusion Trajectory Prior</div>
                  <div class="paper_authors">
                      <b>Yongkang Cheng</b>*, Mingjiang Liang*, Hualin Liang, Shaoli Huang‚Ä†, Wei Liu
                  </div> <b>Equal Contribution</b>
                  <div class="paper_venue"> <b>WACV 2025</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/abs/2410.20358">[Paper]</a></span>
            </div>
            </td>
            </tr>

             <tr>
            <td class="image-column">
               <div class="demo-video">
                  <img src="./images/eccv2024.png" class="publication-image", style="width: 200px; height: auto;">
               </div>
            </td>
            <td class="description-column">
                  <div class="paper_title">SignAvatars: A Large-scale 3D Sign Language Holistic Motion Dataset and Benchmark</div>
                  <div class="paper_authors">
                     Zhengdi Yu, Shaoli Huang‚Ä†, <b>Yongkang Cheng</b>, Tolga Birdal
                  </div>
                  <div class="paper_venue"> <b>ECCV 2024</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/abs/2310.20436">[Paper]</a></span>
               <span class="link"><a target=_blank href="https://signavatars.github.io/">[Project]</a></span>
               <span class="link"><a target=_blank href="https://github.com/ZhengdiYu/SignAvatars">[Code]</a></span>
               <span class="link"><a target=_blank href="https://www.youtube.com/watch?v=GvIjKpgWfxI&feature=youtu.be">[Video]</a></span>
            </div>
            </td>
            </tr>

            <tr>
               <td class="image-column">
                  <div class="demo-video">
                     <img src="./images/ICME2024.gif" class="publication-image", style="width: 200px; height: auto;">
                  </div>
               </td>
               <td class="description-column">
                     <div class="paper_title">ExpGest: Expressive Speaker Generation Using Diffusion Model and Hybrid Audio-Text Guidance</div>
                     <div class="paper_authors">
                         <b>Yongkang Cheng</b>, Mingjiang Liang, Shaoli Huang, Jifeng Ning‚Ä†, Wei Liu
                     </div>
                     <div class="paper_venue"> <b>ICME 2024</b> </div>
                  <div class="paper_materials">
                  <span class="link"><a target=_blank href="https://arxiv.org/abs/2410.09396">[Paper]</a></span>
                  <span class="link"><a target=_blank href="https://github.com/cyk990422/ExpGest">[Code]</a></span>
               </div>
               </td>
               </tr>

            <tr>

				<tr>
<!--             <td class="image-column">
               <div class="demo-video">
                  <img src="./images/icmr.png" class="publication-image", style="width: 200px; height: 120px;">
               </div>
            </td> -->
<!--             <td class="description-column">
                  <div class="paper_title">Inter-Diffusion Generation Model of Speakers and Listeners for Effective Communication</div>
                  <div class="paper_authors">
                  Jinhe Huang*, <b>Yongkang Cheng*‚Ä†</b>, Minghang Yu, Gaoge Han, Jinwei Li, Jing Zhang, Shilei Wang, Xinjian Gu ‚Ä†
                </div> <b>Equal Contribution</b>
                <div> <b>Project Leader</b></div>
                  <div class="paper_venue"> <b>ICMR 2025</b> </div>
               <div class="paper_materials">
                  <span class="link"><a target=_blank href="https://arxiv.org/abs/2505.04996">[Paper]</a></span>
            </div>
            </td>
            </tr>
			
            <tr>

            <td class="image-column">
               <div class="demo-video">
                  <img src="./images/wacv2025rein.gif" class="publication-image", style="width: 200px; height: auto;">
               </div>
            </td>
            <td class="description-column">
                  <div class="paper_title">ReinDiffuse: Crafting Physically Plausible Motions with Reinforced Diffusion Model</div>
                  <div class="paper_authors">
                     Gaoge Han*, Mingjiang Liang*, Jinglei Tang, <b>Yongkang Cheng</b>, Wei Liu, Shaoli Huang‚Ä†
                  </div>
                  <div class="paper_venue"> <b>WACV 2025</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/abs/2410.07296">[Paper]</a></span>
               <span class="link"><a target=_blank href="https://reindiffuse.github.io/">[Project]</a></span>
            </div>
            </td>
            </tr>

			<tr>
            <td class="image-column">
               <div class="demo-video">
                  <img src="./images/SIAM_bub.png" class="publication-image", style="width: 200px; height: 120px;">
               </div>
            </td>
            <td class="description-column">
                  <div class="paper_title">Kernel-aware dynamic convolution for dense prediction</div>
                  <div class="paper_authors">
                  Gaoge Han*, Minjiang Liang*, <b>Yongkang Cheng</b>, Jinglei Tang, Shaoli Huang‚Ä†, Wei Liu
                  <div class="paper_venue"> <b>Pattern Recognition 2025</b> </div>
               <div class="paper_materials">
                  <span class="link"><a target=_blank href="https://www.sciencedirect.com/science/article/abs/pii/S0031320325007915">[Paper]</a></span>
            </div>
            </td>
            </tr> -->

           
            
<!--             <tr>
            <td class="image-column">
               <div class="demo-video">
                  <img src="./images/icassp2024.png" class="publication-image", style="width: 200px; height: auto;">
               </div>
            </td>
            <td class="description-column">
                  <div class="paper_title">Freetalker: Controllable Speech and Text-Driven Gesture Generation Based on Diffusion Models for Enhanced Speaker Naturalness</div>
                  <div class="paper_authors">
                      Sicheng Yang, Zunnan Xu, Haiwei Xue, <b>Yongkang Cheng</b>, Shaoli Huang, Mingming Gong, Zhiyong Wu‚Ä†
                  </div>
                  <div class="paper_venue"> <b>ICASSP 2024</b> </div>
               <div class="paper_materials">
               <span class="link"><a target=_blank href="https://arxiv.org/abs/2401.03476">[Paper]</a></span>
               <span class="link"><a target=_blank href="https://youngseng.github.io/FreeTalker/">[Project]</a></span>
               <span class="link"><a target=_blank href="https://github.com/YoungSeng/FreeTalker">[Code]</a></span>
            </div>
            </td>
            </tr> -->

        </table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
         <tr>
         <td style="padding:20px;width:100%;vertical-align:middle">
           <heading>Experience</heading><p>
         </td>
      </tr>
      <table class="publication-table">
            <td class="image-column">
               <div class="demo-video">
                  <img src="./images/txailab.jpeg" class="publication-image", style="width: 200; height: 120px;">
               </div>
            </td>
            <td class="description-column">
                  <div class="paper_title">	
                     <b>Research Intern, Tencent AI Laboratory.</b> </div>
                     <div class="paper_venue"> Aug. 2022 - Dec. 2024 </div>
            </td>
            </tr>
         </p>
         </td>
         <td class="image-column">
            <div class="demo-video">
               <img src="./images/Screenshot 2025-07-09 14:10:54.png" class="publication-image", style="width: 200; height: 120px;">
            </div>
         </td>
         <td class="description-column">
               <div class="paper_title">	
                  <b>Research Intern, Astribot.</b> </div>
                  <div class="paper_venue"> Jan. 2025 - Mar. 2025 </div>
         </td>
         </tr>
      </p>
<!--       </td>
      <td class="image-column">
         <div class="demo-video">
            <img src="./images/Screenshot 2025-07-09 14:10:54.png" class="publication-image", style="width: 200; height: 120px;">
         </div>
      </td>
      <td class="description-column">
            <div class="paper_title">	
               <b>Research Scientist, Astribot.</b> </div>
               <div class="paper_venue"> Apr. 2025 - Jul. 2025 </div>
      </td>
      </tr>
   </p> -->
   </td>
   <td class="image-column">
      <div class="demo-video">
         <img src="./images/agi.png" class="publication-image", style="width: 200; height: 120px;">
      </div>
   </td>
   <td class="description-column">
         <div class="paper_title">	
            <b>Research Scientist, AgiBot.</b> </div>
            <div class="paper_venue"> Jul. 2025 - Aug. 2025 </div>
   </td>
   </tr>
</p>
</td>
       </tr>
     </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
<!-- <center>
